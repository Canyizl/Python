#  《机器学习》 —— 周志华

### 1.绪论

预测的是离散值，称为”分类“；

预测的是连续值，称为"回归"；



### 2.模型评估与选择

总数据集：训练集+验证集+测试集

经验误差：在训练集上的误差

泛化误差：在”未来“样本上的误差

#### 2.2评估方法

##### 2.2.1留出法：

​	常见做法是大约2/3~4/5的样本用于训练，剩余用于测试



##### 2.2.2交叉验证法（k折交叉验证）：

​	将D划分为k个大小相似的互斥子集，每次用k-1个作为训练集，余下的那个作为测试集；这样就可以获得k组训练/测试集，从而可进行k次训练和测试，最终返回k个测试结果的均值。

​	k最常用取值为10，其他常用k值有5、20等。



##### 2.2.3自助法：

​	给定包含m个样本的数据集D，每次随机选中一个样本拷贝进入D‘，再将样本放回初始数据集D，使得下次仍有可能将其选中，将这个过程重复m次，就得到了包含m个样本的数据集D’。

​	显然D中有一部分样本会在D‘中多次出现，而另一部分样本不会。

在m次采样中始终不被采到的概率是（1-1/m）^m.极限为1/e=0.368.

​	于是我们可以将D’用作训练集，D\D'用作测试集，这样实际评估和期望评估的模型都有m个训练样本，而还有总量约1/3的、没在训练集中出现的样本用于测试。

​	常用于数据集较小、难以有效划分的训练/测试集。当数据量足够的时候，改变了初始的分布会引入估计偏差，因此用留出法和交叉验证法更常用。



#### 2.3性能度量

##### 	2.3.1 错误率与精度

​	错误率：分类错误的样本数占样本总数的比例

​	精度: 分类正确的样本数占样本总数的比例

##### 	2.3.2 查准率、查全率与F1

![分类结果混淆矩阵](C:\Users\Administrator\Desktop\Typora\图片\分类结果混淆矩阵.png)

查准率P：TP/TP+FP 真正例/预测总正例

查全率R:	TP/TP+FN 真正例/总正例

”平衡点“（BEP）：”查准率=查全率“ 衡量了学习器的优越

更常用的是F1度量: ![F1](C:\Users\Administrator\Desktop\Typora\图片\F1.png)

​		F1 = 2·P·R/(P+R) = 2·TP / 样例总数+TP-TN

通过对P和R的重视度不同，F1度量的一般形式——Fp![Fp](C:\Users\Administrator\Desktop\Typora\图片\Fp.png)

其中β>0，度量了查全率对查准率的相对重要性；

β=1时退化为标准的F1；

β>1时，查全率有更大影响；

β<1时，查准率有更大影响；



#### 6.SVM支持向量机

线性可分问题-->基础SVM

线性不可分-->维度爆炸--->对偶问题--->核函数

噪音问题--->软间隔



#### 基础知识补充：

##### 1.zero-mean normalization

最常见的标准化方法就是Z标准化，也是SPSS中最为常用的标准化方法，spss默认的标准化方法就是z-score标准化。

x* = (x - μ ) / σ 

μ为所有样本数据的均值，σ为所有样本数据的标准差。

Python实现:

```python
def shujuguiyi(a,b,M):
    j = 0
    guiyi = np.empty([a,b])            #empty函数
    for j in range(b):
        guiyi[:,j] = (M[:,j] - np.mean(M[:,j])) / np.std(M[:,j])   #数据归一化标准差法
    return guiyi
#定义数据归一函数
```

注意：该种标准化方式要求原始数据的分布可以近似为高斯分布，否则效果会变得很糟糕。适用于属性A的最大值和最小值未知的情况，或有超出取值范围的离群数据的情况。

# 论文摘记

2020 09 22

重点：CVPR2020关于视频理解的论文(英文)

#### 1.基于人眼视觉认知机制的仿生感知方法研究_张培江

##### 研究方向:

​	智能感知：基于人眼仿生感知与机器视觉技术相结合的视觉感知系统



##### 解决问题：

1.随着加工机器的逐渐增多、协同化加工需求逐渐提高，机器与机器之间需要进行状态信息共享时，就会导致多物理信息的冗余。能够有效的利用好视觉信息，提高视觉感知能力。

2.解决传统机器视觉不足和提高机器的自我感知能力。



##### 创新点：

基于视觉认知机制

（自底向上，自顶向下的仿生感知方法，注意力驱动）



##### 主要内容：

1.视觉系统及生理构造：格式塔（Gestalt），视觉通路：腹侧通路（What通路）和背侧通路（Where通路），视觉注意机制：自底向上、自顶向下



2.仿生感知原理：各种感知模块传感器将信息传递到信息处理单元，中央处理模块实现对各个感知模块信息的特征提取、融合和处理，模拟大脑皮层的信息处理机制实现仿生感知。

(2.5.仿生感知和认知学科基础：基本理论：符号主义、联结主义、行为主义.)



3.基于人眼视觉主义机制的仿生感知模型:该文根据视觉系统信息处理过程主要分为两种:

第一种为无意识的视觉注意目标区域搜索:主要由自底向上驱动,没有任何需求的时候会首先放眼全局,根据刺激找到显著区域,将目光集中查看.

第二种为有意识的视觉注意目标区域搜索过程:首先在知识库内寻找到所要注意目标的各种特征信息,带着特征的相似性去筛选类似特征,找到最接近的目标进行视觉注意.



4.最优质量图像获取方法:（P37）

​		图像质量评价体系及方法：

​	图像质量及主要影响因素：

1）亮度特征（人眼主观视觉亮度Sn与客观视觉感知成对数关系）

2）对比敏感度特征 

3）色度特征

4）掩膜特征（CSF函数来构建模型）

5）中央凹特性

6）多通道特性（高频表现出结构和轮廓特性、中频为视觉关注区域、低频表现出细节和纹理信息）

​	评价体系构建及指标量化方法:

1)主观图像质量评价体系：主平均主观分（MOS）、差分平均主观分（DMOS、更普遍）

2）客观图像质量评价体系：全参考评价（FR）、部分参考评价（RR）、无参考评价(NR)

​	基于Siamese网络的有参考评价方法(IQA-FR):P46

​	基于卷积神经网络的无参考评价方法（IQA-NR:ADAM

​	图像质量优化问题：粒子群算法



5.基于人眼视觉选择注意力集中机制的图像处理方法

​	视觉显著区域的度量：

1）内部特征提取法：对称性、离散矩变换、灰度直方图熵

2）外部特征提取法：亮度差异，梯度强度和方向、亮度和曲率，颜色、亮度、方向。

3）综合特征提取法

​	基于自底向上视觉选择性注意机制的方法：

特点：数据驱动、自动加工

模型：大多来自于Itti的视觉显著模型。核心:对提取到的初级视觉特征进行显著性度量形成初级视觉注意显著图。人眼一次只会产生一个注意点，在一幅图中出现多个显著特征点时，会相互竞争各自的特征区域，通过竞争机制得到显著性较大的区域，成为自底向上机制的视觉注意区域。

​	基于二维Garbor滤波器的显著图像处理方法：对局部信息提取、对图像边缘信息反映敏感，能够得到较好的方向特性和尺度特性。其次对光亮度不敏感，有较好的光适应能力。

​	图像初级特征提取及处理方法:

1）亮度特征提取：提取输入图像红、绿、蓝三个颜色通道r(t)、g、b。其中t表示尺度

2)颜色特征：拮抗原理描述了人眼视觉系统中视觉信息到神经节上的活动，核心就算采取互补色的方式，以相反方向刺激视觉神经。因此采用红R(t)、黄Y、蓝B、绿G四个通道值表示：

R = r - (g + b) / 2

G = g - (r + b) / 2

B = b - (r + g) / 2

Y = (r + g) - 2*(|r-g|+b)

3)方向特征：二维Gabor滤波器 

​	基于数据驱动的多显著特征融合：

1）亮度特征显著图: 一般对中间亮周围暗或者周边暗中间亮的区域敏感，计算中央周边差值可以表达对比度，也就表达了亮度显著图。

2）颜色特征: 提取RG表示红绿，BY表示黄蓝

3）方向显著：局部的方向对比度

4）视觉显著度量：视差

5）信息整合:计算三类特征视差图的平均值和方差

6）归一化特征组合

​		自顶向下视觉显著性

​	基于支持向量机训练的视觉注意模型（解决小样本、高维度、非线性问题表现出优势，常用于模式识别、分类和回归）：线性核函数

​	图像视觉显著特征选择: 初级、中级、高级。初级主要是底层视觉注意特征，如亮度、颜色、方向，还加入了可控金字塔能量特征。眼动特征作为中级和高级。



6.基于目标任务驱动和注意力机制的视觉仿生感知方法

基于迁移学习的目标任务驱动



7.仿真、实践、总结



#### 2.基于听觉脑认知规律的情感计算方法研究_薄洪健

##### 研究方向：

​	听觉情感脑认知规律，声音信号与脑电信号的情感分析和识别方法。

​	情感计算。

##### 解决问题：

​	感知情感所引起的生理及行为反应，建立”情感模型“，达到智能化人机交互。

##### 创新点：

​	1.针对长时听觉情感认知分析

​	2.脑启发的情感识别技术

##### 主要内容：

1.听觉情感神经基础：

​	情感描述模型：PAD、VA

​	情感认知神经机制：1）大脑对不同类型的情感认知的脑区是不同的；2）听觉诱发的积极情感在大脑左侧半球的优势；3）听觉情感调节了众多脑功能区域，说明了边缘系统在听觉诱发情感的大脑活动中起到重要的作用。

听觉情感认知实验范式：针对图像、声响等短时刺激。

2.脑活动情感状态分析：

​	情感脑电信号特征提取与分类识别方法：特征：时域和频域特征。

​	识别：有监督识别，常见有神经网络、SVM、贝叶斯网络决策树。

！！深度信念网络（DBN），提取差分熵（DE）特征作为网络输入，平均准确率为89.12%

3.音频情感计算技术：2010：openSMILE ；2015：SVM和遗传算法；

2016：CNN与LSTM

​	离散语音情感识别问题实际上是一个模式识别问题，多使用HMM、GMM、ANN、SVM、决策树等分类器。

​	Basque离散情感语料库上用GMM和SVM

​	维度情感预测算法包括：PLS、SVR、RNN、LSTM、k-NN等，其中SVR优于k-NN

​	LSTM-RNN用于多模态维度情感识别。概率神经网络（PNN）和隐马尔可夫模型（HMM）对声学参数统计特性和时序特性进行处理。

4.脑启发的情感分类识别方法

5.听觉情感认知研究存在的主要问题：1）缺少针对长时听觉情感认知实验范式；2）用于听觉情感分析的脑电数据集种类单一；3）听觉长时情感脑电认知规律分析方法缺乏

​	听觉情感计算研究存在的主要问题：1）没有考虑情感认知的个体差异；2）没有适用于情感识别的理想学习特征；3）情感计算研究没有进一步从脑科学的研发成果中得到启发。

6.基于自动听觉事件检测的长时脑电成分分析方法：

​	声音三要素：音高、音强、音色。选择过零率（ZCR）、均方根（RMS）、频谱质心（SC）、频谱通量（SF）四个声学特征。SF表征音高、均方根表征音强、频谱质心是频谱能量的集中点（中高频与低频的比例）、频谱通量描述的是相邻帧频谱的变化情况。

​	事件点的定义：1）波动变化明显；2）波动事件尽可能短；3）前后无明显波动。

​	基于小波变换的音频事件点检测方法：

​		基于频带能量差异的长时脑地形图分析技术

​		基于任务无关的声响情感认知实验过程设计

7.音乐情感刺激样本选取（实验）

​	规律总结:1)听觉情感认知具有短时特性；2）具有频带差异规律；3）具有脑区差异规律；4）具有适应性。

8.基于常数Q变换的自适应脑电分析方法：

​	音阶频率不是等间隔，而是按照指数规律。

基于CQT的自适应脑电频谱分析：

基于情感脑电频谱相应差异度的特征提取：

​	个体差异分析（EESD）

基于EESD优化的自适应频谱估计方法：

9.基于公共空间模式（CSP）的脑电空间特征分析方法：

​	CSP算法是两分类任务下的空域滤波特征提取算法，原理是找出一个最优的公共空间滤波器，在最大化一类方差的同时最小化另一类方差。其次，利用矩阵的对角化，找到差异最大的最优空间滤波器进行投影，得到两类任务具有较高区分度的特征向量。（重要信息主要集中在头部和尾部）

​	基于CNN的CSP特征分析方法

​	基于拓扑约束保持的TCM-CSP情感脑电计算方法

10.基于γ分布的特征分析：

​	γ分布是统计学的一种连续概率函数，能有效地表达连续时间段内变量的演变趋势。

基于表征相异性矩阵（RDM）的情感分布矩阵建立：

​	余弦距离（比欧式距离，更能刻画两个特征向量在方向上的差异。）

基于Lasso回归的音乐情感预测



#### 3.人脑记忆机制启发下图像存储和提取的认知神经计算建模_董丽萍

##### 研究方向:



##### 解决问题：



##### 创新点：



##### 主要内容：





#### 4.Brain Inspired Cognitive Model with Attention for Self-Driving Cars

##### 研究方向:

​	CMA(brain-inspired cognitive model with attention)

##### 解决问题：

​	 1.detection of the free space and boundaries of the current and adjacent lanes.（检测自由空间和边界的现行车道、相邻车道。）

​	 2.estimation of obstacle distance and vehicle attitude（障碍物距离和车辆姿态估计）

 	3.learning of driving behavior and decision making from human driver. （学习人类的驾驶习惯和判断）

​	 4.accept external navigating instructions during an end-to-end
driving process.（在端到端驾驶过程中，依然能接受外界的导航指引。）

##### 创新点:

​	Handle the spatial-temporal relationships

##### 主要内容：

1.Abstract——CMA（brain-inspired cognitive model with attention）

​	Three parts: 

a CNN(convolutional neural network) for simulating human visual cortex, (卷积神经网络来模拟人类的视觉皮层)

a Cognitive map built to describe relationships between objects in complex traffic scene,（描述复杂场景中物体关系的认知地图）

a RNN（recurrent neural network）that combines with the real-time updated cognitive map to implement attention mechanism and long-short term memory.（一种结合实时更新的认知地图来实现注意机制的循环神经网络和长期短期记忆）



2.Introduction——Two popular paradigms:

​	percepiton - driven: establish a detailed representation. lacks the self-learning ability.

​	end-to-end : based on CNN and GPU.

3.built a model  with attention:

​	**CNN** for the processing of the visual information.--->Simulating Human Visual Cortex

​	**RNN** for the processing of the sequence data( video sequence classification and natural language processing tasks.)-----> Simulating Human Motor Cortex

​	**Cognitive map**  (defined in this paper is essentially a structured description of vehicle state and scene data in the past.) combines **long-short term memory**-----> human driving ability to understand about traffic scene and to make decisions of driving.

4.Related work

CNN, to map an input image directly to a deviation between vehicle and lane boundary.

We only need to know if there is a obstacle in our lane and how far the obstacle is.  it is a more convenient and efficient way to represent the obstacle as a point instead of a bounding box.

FCN-LSTM,which can predict egomotion of the vehicle by its previous state.

5.CMA

I): Perception Simulating Human Visual Cortex

​	input images as **It** = {It_m, It_l , It_r}, which are captured by the middle, left and right cameras.

​	output vector Xt = [pl_t, pl_b, pr_t, pr_b, po]

​	To achieve a high performance in real-time, simple and shallow: 		Five convolutional layers, 

​		without pooling layer(we use the network to locate feature points rather than classify), 

​		three fully connected layers.

​	obtain the perception results {Xt_m, Xt_l , Xt_r}

II): Planning and Control Simulating Human Motor Cortex

​	The structured description of cognitive map C t with the vehicle states VStates, formed as Ct = {Xt_m,Xt_l,Xt_r,Dt_i,Vstates}

​	Long Short-Term Memory (LSTM) is a basic unit of recurrent neural network.One cell in a LSTM unit is controlled by three gates (input gate, output gate and forget gate). Forgot gate and input gate use a sigmoid function, while output and cell state are transformed with tanh.

​		three LSTM layers, making the network learn higher-level temporal representations.

6.RVD Dataset

7.Experiments

​	Free-space: evaluate the consistency between the model output and accurately labeled ground truth.(We choose the criteria of precision,recall and F-measure)

